"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  Analytics: () => Analytics,
  MultiRegionRatelimit: () => MultiRegionRatelimit,
  Ratelimit: () => RegionRatelimit
});
module.exports = __toCommonJS(src_exports);

// src/analytics.ts
var import_core_analytics = require("@upstash/core-analytics");
var Analytics = class {
  analytics;
  table = "events";
  constructor(config) {
    this.analytics = new import_core_analytics.Analytics({
      // @ts-expect-error we need to fix the types in core-analytics, it should only require the methods it needs, not the whole sdk
      redis: config.redis,
      window: "1h",
      prefix: config.prefix ?? "@upstash/ratelimit",
      retention: "90d"
    });
  }
  /**
   * Try to extract the geo information from the request
   *
   * This handles Vercel's `req.geo` and  and Cloudflare's `request.cf` properties
   * @param req
   * @returns
   */
  extractGeo(req) {
    if (typeof req.geo !== "undefined") {
      return req.geo;
    }
    if (typeof req.cf !== "undefined") {
      return req.cf;
    }
    return {};
  }
  async record(event) {
    await this.analytics.ingest(this.table, event);
  }
  async series(filter, cutoff) {
    const timestampCount = Math.min(
      (this.analytics.getBucket(Date.now()) - this.analytics.getBucket(cutoff)) / (60 * 60 * 1e3),
      256
    );
    return this.analytics.aggregateBucketsWithPipeline(this.table, filter, timestampCount);
  }
  async getUsage(cutoff = 0) {
    const timestampCount = Math.min(
      (this.analytics.getBucket(Date.now()) - this.analytics.getBucket(cutoff)) / (60 * 60 * 1e3),
      256
    );
    const records = await this.analytics.getAllowedBlocked(this.table, timestampCount);
    return records;
  }
  async getUsageOverTime(timestampCount, groupby) {
    const result = await this.analytics.aggregateBucketsWithPipeline(this.table, groupby, timestampCount);
    return result;
  }
  async getMostAllowedBlocked(timestampCount, getTop) {
    getTop = getTop ?? 5;
    return this.analytics.getMostAllowedBlocked(this.table, timestampCount, getTop);
  }
};

// src/cache.ts
var Cache = class {
  /**
   * Stores identifier -> reset (in milliseconds)
   */
  cache;
  constructor(cache) {
    this.cache = cache;
  }
  isBlocked(identifier) {
    if (!this.cache.has(identifier)) {
      return { blocked: false, reset: 0 };
    }
    const reset = this.cache.get(identifier);
    if (reset < Date.now()) {
      this.cache.delete(identifier);
      return { blocked: false, reset: 0 };
    }
    return { blocked: true, reset };
  }
  blockUntil(identifier, reset) {
    this.cache.set(identifier, reset);
  }
  set(key, value) {
    this.cache.set(key, value);
  }
  get(key) {
    return this.cache.get(key) || null;
  }
  incr(key) {
    let value = this.cache.get(key) ?? 0;
    value += 1;
    this.cache.set(key, value);
    return value;
  }
  pop(key) {
    this.cache.delete(key);
  }
  empty() {
    this.cache.clear();
  }
};

// src/duration.ts
function ms(d) {
  const match = d.match(/^(\d+)\s?(ms|s|m|h|d)$/);
  if (!match) {
    throw new Error(`Unable to parse window size: ${d}`);
  }
  const time = Number.parseInt(match[1]);
  const unit = match[2];
  switch (unit) {
    case "ms":
      return time;
    case "s":
      return time * 1e3;
    case "m":
      return time * 1e3 * 60;
    case "h":
      return time * 1e3 * 60 * 60;
    case "d":
      return time * 1e3 * 60 * 60 * 24;
    default:
      throw new Error(`Unable to parse window size: ${d}`);
  }
}

// src/lua-scripts/multi.ts
var fixedWindowLimitScript = `
	local key           = KEYS[1]
	local id            = ARGV[1]
	local window        = ARGV[2]
	local incrementBy   = tonumber(ARGV[3])

	redis.call("HSET", key, id, incrementBy)
	local fields = redis.call("HGETALL", key)
	if #fields == 2 and tonumber(fields[2])==incrementBy then
	-- The first time this key is set, and the value will be equal to incrementBy.
	-- So we only need the expire command once
	  redis.call("PEXPIRE", key, window)
	end

	return fields
`;
var fixedWindowRemainingTokensScript = `
      local key = KEYS[1]
      local tokens = 0

      local fields = redis.call("HGETALL", key)

      return fields
    `;
var slidingWindowLimitScript = `
	local currentKey    = KEYS[1]           -- identifier including prefixes
	local previousKey   = KEYS[2]           -- key of the previous bucket
	local tokens        = tonumber(ARGV[1]) -- tokens per window
	local now           = ARGV[2]           -- current timestamp in milliseconds
	local window        = ARGV[3]           -- interval in milliseconds
	local requestId     = ARGV[4]           -- uuid for this request
	local incrementBy   = tonumber(ARGV[5]) -- custom rate, default is  1

	local currentFields = redis.call("HGETALL", currentKey)
	local requestsInCurrentWindow = 0
	for i = 2, #currentFields, 2 do
	requestsInCurrentWindow = requestsInCurrentWindow + tonumber(currentFields[i])
	end

	local previousFields = redis.call("HGETALL", previousKey)
	local requestsInPreviousWindow = 0
	for i = 2, #previousFields, 2 do
	requestsInPreviousWindow = requestsInPreviousWindow + tonumber(previousFields[i])
	end

	local percentageInCurrent = ( now % window) / window
	if requestsInPreviousWindow * (1 - percentageInCurrent ) + requestsInCurrentWindow >= tokens then
	  return {currentFields, previousFields, false}
	end

	redis.call("HSET", currentKey, requestId, incrementBy)

	if requestsInCurrentWindow == 0 then 
	  -- The first time this key is set, the value will be equal to incrementBy.
	  -- So we only need the expire command once
	  redis.call("PEXPIRE", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second
	end
	return {currentFields, previousFields, true}
`;
var slidingWindowRemainingTokensScript = `
	local currentKey    = KEYS[1]           -- identifier including prefixes
	local previousKey   = KEYS[2]           -- key of the previous bucket
	local now         	= ARGV[1]           -- current timestamp in milliseconds
  	local window      	= ARGV[2]           -- interval in milliseconds

	local currentFields = redis.call("HGETALL", currentKey)
	local requestsInCurrentWindow = 0
	for i = 2, #currentFields, 2 do
	requestsInCurrentWindow = requestsInCurrentWindow + tonumber(currentFields[i])
	end

	local previousFields = redis.call("HGETALL", previousKey)
	local requestsInPreviousWindow = 0
	for i = 2, #previousFields, 2 do
	requestsInPreviousWindow = requestsInPreviousWindow + tonumber(previousFields[i])
	end

	local percentageInCurrent = ( now % window) / window
  	requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)
	
	return requestsInCurrentWindow + requestsInPreviousWindow
`;

// src/lua-scripts/reset.ts
var resetScript = `
      local pattern = KEYS[1]

      -- Initialize cursor to start from 0
      local cursor = "0"

      repeat
          -- Scan for keys matching the pattern
          local scan_result = redis.call('SCAN', cursor, 'MATCH', pattern)

          -- Extract cursor for the next iteration
          cursor = scan_result[1]

          -- Extract keys from the scan result
          local keys = scan_result[2]

          for i=1, #keys do
          redis.call('DEL', keys[i])
          end

      -- Continue scanning until cursor is 0 (end of keyspace)
      until cursor == "0"
    `;

// src/ratelimit.ts
var Ratelimit = class {
  limiter;
  ctx;
  prefix;
  timeout;
  analytics;
  constructor(config) {
    this.ctx = config.ctx;
    this.limiter = config.limiter;
    this.timeout = config.timeout ?? 5e3;
    this.prefix = config.prefix ?? "@upstash/ratelimit";
    this.analytics = config.analytics ? new Analytics({
      redis: Array.isArray(this.ctx.redis) ? this.ctx.redis[0] : this.ctx.redis,
      prefix: this.prefix
    }) : void 0;
    if (config.ephemeralCache instanceof Map) {
      this.ctx.cache = new Cache(config.ephemeralCache);
    } else if (typeof config.ephemeralCache === "undefined") {
      this.ctx.cache = new Cache(/* @__PURE__ */ new Map());
    }
  }
  /**
   * Determine if a request should pass or be rejected based on the identifier and previously chosen ratelimit.
   *
   * Use this if you want to reject all requests that you can not handle right now.
   *
   * @example
   * ```ts
   *  const ratelimit = new Ratelimit({
   *    redis: Redis.fromEnv(),
   *    limiter: Ratelimit.slidingWindow(10, "10 s")
   *  })
   *
   *  const { success } = await ratelimit.limit(id)
   *  if (!success){
   *    return "Nope"
   *  }
   *  return "Yes"
   * ```
   *
   * @param req.rate - The rate at which tokens will be added or consumed from the token bucket. A higher rate allows for more requests to be processed. Defaults to 1 token per interval if not specified.
   *
   * Usage with `req.rate`
   * @example
   * ```ts
   *  const ratelimit = new Ratelimit({
   *    redis: Redis.fromEnv(),
   *    limiter: Ratelimit.slidingWindow(100, "10 s")
   *  })
   *
   *  const { success } = await ratelimit.limit(id, {rate: 10})
   *  if (!success){
   *    return "Nope"
   *  }
   *  return "Yes"
   * ```
   */
  limit = async (identifier, req) => {
    const key = [this.prefix, identifier].join(":");
    let timeoutId = null;
    try {
      const arr = [this.limiter().limit(this.ctx, key, req?.rate)];
      if (this.timeout > 0) {
        arr.push(
          new Promise((resolve) => {
            timeoutId = setTimeout(() => {
              resolve({
                success: true,
                limit: 0,
                remaining: 0,
                reset: 0,
                pending: Promise.resolve()
              });
            }, this.timeout);
          })
        );
      }
      const res = await Promise.race(arr);
      if (this.analytics) {
        try {
          const geo = req ? this.analytics.extractGeo(req) : void 0;
          const analyticsP = this.analytics.record({
            identifier,
            time: Date.now(),
            success: res.success,
            ...geo
          }).catch((err) => {
            let errorMessage = "Failed to record analytics";
            if (`${err}`.includes("WRONGTYPE")) {
              errorMessage = `
Failed to record analytics. See the information below:

This can occur when you uprade to Ratelimit version 1.1.2
or later from an earlier version.

This occurs simply because the way we store analytics data
has changed. To avoid getting this error, disable analytics
for *an hour*, then simply enable it back.

`;
            }
            console.warn(errorMessage, err);
          });
          res.pending = Promise.all([res.pending, analyticsP]);
        } catch (err) {
          console.warn("Failed to record analytics", err);
        }
      }
      return res;
    } finally {
      if (timeoutId) {
        clearTimeout(timeoutId);
      }
    }
  };
  /**
   * Block until the request may pass or timeout is reached.
   *
   * This method returns a promise that resolves as soon as the request may be processed
   * or after the timeout has been reached.
   *
   * Use this if you want to delay the request until it is ready to get processed.
   *
   * @example
   * ```ts
   *  const ratelimit = new Ratelimit({
   *    redis: Redis.fromEnv(),
   *    limiter: Ratelimit.slidingWindow(10, "10 s")
   *  })
   *
   *  const { success } = await ratelimit.blockUntilReady(id, 60_000)
   *  if (!success){
   *    return "Nope"
   *  }
   *  return "Yes"
   * ```
   */
  blockUntilReady = async (identifier, timeout) => {
    if (timeout <= 0) {
      throw new Error("timeout must be positive");
    }
    let res;
    const deadline = Date.now() + timeout;
    while (true) {
      res = await this.limit(identifier);
      if (res.success) {
        break;
      }
      if (res.reset === 0) {
        throw new Error("This should not happen");
      }
      const wait = Math.min(res.reset, deadline) - Date.now();
      await new Promise((r) => setTimeout(r, wait));
      if (Date.now() > deadline) {
        break;
      }
    }
    return res;
  };
  resetUsedTokens = async (identifier) => {
    const pattern = [this.prefix, identifier].join(":");
    await this.limiter().resetTokens(this.ctx, pattern);
  };
  getRemaining = async (identifier) => {
    const pattern = [this.prefix, identifier].join(":");
    return await this.limiter().getRemaining(this.ctx, pattern);
  };
};

// src/multi.ts
function randomId() {
  let result = "";
  const characters = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
  const charactersLength = characters.length;
  for (let i = 0; i < 16; i++) {
    result += characters.charAt(Math.floor(Math.random() * charactersLength));
  }
  return result;
}
var MultiRegionRatelimit = class extends Ratelimit {
  /**
   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithn of your choice.
   */
  constructor(config) {
    super({
      prefix: config.prefix,
      limiter: config.limiter,
      timeout: config.timeout,
      analytics: config.analytics,
      ctx: {
        redis: config.redis,
        cache: config.ephemeralCache ? new Cache(config.ephemeralCache) : void 0
      }
    });
  }
  /**
   * Each request inside a fixed time increases a counter.
   * Once the counter reaches the maximum allowed number, all further requests are
   * rejected.
   *
   * **Pro:**
   *
   * - Newer requests are not starved by old ones.
   * - Low storage cost.
   *
   * **Con:**
   *
   * A burst of requests near the boundary of a window can result in a very
   * high request rate because two windows will be filled with requests quickly.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - A fixed timeframe
   */
  static fixedWindow(tokens, window) {
    const windowDuration = ms(window);
    return () => ({
      async limit(ctx, identifier, rate) {
        if (ctx.cache) {
          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
          if (blocked) {
            return {
              success: false,
              limit: tokens,
              remaining: 0,
              reset: reset2,
              pending: Promise.resolve()
            };
          }
        }
        const requestId = randomId();
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        const incrementBy = rate ? Math.max(1, rate) : 1;
        const dbs = ctx.redis.map((redis) => ({
          redis,
          request: redis.eval(
            fixedWindowLimitScript,
            [key],
            [requestId, windowDuration, incrementBy]
          )
        }));
        const firstResponse = await Promise.any(dbs.map((s) => s.request));
        const usedTokens = firstResponse.reduce((accTokens, usedToken, index) => {
          let parsedToken = 0;
          if (index % 2) {
            parsedToken = Number.parseInt(usedToken);
          }
          return accTokens + parsedToken;
        }, 0);
        const remaining = tokens - usedTokens;
        async function sync() {
          const individualIDs = await Promise.all(dbs.map((s) => s.request));
          const allIDs = Array.from(
            new Set(
              individualIDs.flatMap((_) => _).reduce((acc, curr, index) => {
                if (index % 2 === 0) {
                  acc.push(curr);
                }
                return acc;
              }, [])
            ).values()
          );
          for (const db of dbs) {
            const usedDbTokens = (await db.request).reduce(
              (accTokens, usedToken, index) => {
                let parsedToken = 0;
                if (index % 2) {
                  parsedToken = Number.parseInt(usedToken);
                }
                return accTokens + parsedToken;
              },
              0
            );
            const dbIds = (await db.request).reduce((ids, currentId, index) => {
              if (index % 2 === 0) {
                ids.push(currentId);
              }
              return ids;
            }, []);
            if (usedDbTokens >= tokens) {
              continue;
            }
            const diff = allIDs.filter((id) => !dbIds.includes(id));
            if (diff.length === 0) {
              continue;
            }
            for (const requestId2 of diff) {
              await db.redis.hset(key, { [requestId2]: incrementBy });
            }
          }
        }
        const success = remaining > 0;
        const reset = (bucket + 1) * windowDuration;
        if (ctx.cache && !success) {
          ctx.cache.blockUntil(identifier, reset);
        }
        return {
          success,
          limit: tokens,
          remaining,
          reset,
          pending: sync()
        };
      },
      async getRemaining(ctx, identifier) {
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        const dbs = ctx.redis.map((redis) => ({
          redis,
          request: redis.eval(fixedWindowRemainingTokensScript, [key], [null])
        }));
        const firstResponse = await Promise.any(dbs.map((s) => s.request));
        const usedTokens = firstResponse.reduce((accTokens, usedToken, index) => {
          let parsedToken = 0;
          if (index % 2) {
            parsedToken = Number.parseInt(usedToken);
          }
          return accTokens + parsedToken;
        }, 0);
        return Math.max(0, tokens - usedTokens);
      },
      async resetTokens(ctx, identifier) {
        const pattern = [identifier, "*"].join(":");
        if (ctx.cache) {
          ctx.cache.pop(identifier);
        }
        for (const db of ctx.redis) {
          await db.eval(resetScript, [pattern], [null]);
        }
      }
    });
  }
  /**
   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage
   * costs than `slidingLogs` and improved boundary behavior by calculating a
   * weighted score between two windows.
   *
   * **Pro:**
   *
   * Good performance allows this to scale to very high loads.
   *
   * **Con:**
   *
   * Nothing major.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - The duration in which the user can max X requests.
   */
  static slidingWindow(tokens, window) {
    const windowSize = ms(window);
    const windowDuration = ms(window);
    return () => ({
      async limit(ctx, identifier, rate) {
        const requestId = randomId();
        const now = Date.now();
        const currentWindow = Math.floor(now / windowSize);
        const currentKey = [identifier, currentWindow].join(":");
        const previousWindow = currentWindow - 1;
        const previousKey = [identifier, previousWindow].join(":");
        const incrementBy = rate ? Math.max(1, rate) : 1;
        const dbs = ctx.redis.map((redis) => ({
          redis,
          request: redis.eval(
            slidingWindowLimitScript,
            [currentKey, previousKey],
            [tokens, now, windowDuration, requestId, incrementBy]
            // lua seems to return `1` for true and `null` for false
          )
        }));
        const percentageInCurrent = now % windowDuration / windowDuration;
        const [current, previous, success] = await Promise.any(dbs.map((s) => s.request));
        if (success) {
          current.push(requestId, incrementBy.toString());
        }
        const previousUsedTokens = previous.reduce((accTokens, usedToken, index) => {
          let parsedToken = 0;
          if (index % 2) {
            parsedToken = Number.parseInt(usedToken);
          }
          return accTokens + parsedToken;
        }, 0);
        const currentUsedTokens = current.reduce((accTokens, usedToken, index) => {
          let parsedToken = 0;
          if (index % 2) {
            parsedToken = Number.parseInt(usedToken);
          }
          return accTokens + parsedToken;
        }, 0);
        const previousPartialUsed = Math.ceil(previousUsedTokens * (1 - percentageInCurrent));
        const usedTokens = previousPartialUsed + currentUsedTokens;
        const remaining = tokens - usedTokens;
        async function sync() {
          const res = await Promise.all(dbs.map((s) => s.request));
          const allCurrentIds = Array.from(
            new Set(
              res.flatMap(([current2]) => current2).reduce((acc, curr, index) => {
                if (index % 2 === 0) {
                  acc.push(curr);
                }
                return acc;
              }, [])
            ).values()
          );
          for (const db of dbs) {
            const [current2, _previous, _success] = await db.request;
            const dbIds = current2.reduce((ids, currentId, index) => {
              if (index % 2 === 0) {
                ids.push(currentId);
              }
              return ids;
            }, []);
            const usedDbTokens = current2.reduce((accTokens, usedToken, index) => {
              let parsedToken = 0;
              if (index % 2) {
                parsedToken = Number.parseInt(usedToken);
              }
              return accTokens + parsedToken;
            }, 0);
            if (usedDbTokens >= tokens) {
              continue;
            }
            const diff = allCurrentIds.filter((id) => !dbIds.includes(id));
            if (diff.length === 0) {
              continue;
            }
            for (const requestId2 of diff) {
              await db.redis.hset(currentKey, { [requestId2]: incrementBy });
            }
          }
        }
        const reset = (currentWindow + 1) * windowDuration;
        if (ctx.cache && !success) {
          ctx.cache.blockUntil(identifier, reset);
        }
        return {
          success: Boolean(success),
          limit: tokens,
          remaining: Math.max(0, remaining),
          reset,
          pending: sync()
        };
      },
      async getRemaining(ctx, identifier) {
        const now = Date.now();
        const currentWindow = Math.floor(now / windowSize);
        const currentKey = [identifier, currentWindow].join(":");
        const previousWindow = currentWindow - 1;
        const previousKey = [identifier, previousWindow].join(":");
        const dbs = ctx.redis.map((redis) => ({
          redis,
          request: redis.eval(
            slidingWindowRemainingTokensScript,
            [currentKey, previousKey],
            [now, windowSize]
            // lua seems to return `1` for true and `null` for false
          )
        }));
        const usedTokens = await Promise.any(dbs.map((s) => s.request));
        return Math.max(0, tokens - usedTokens);
      },
      async resetTokens(ctx, identifier) {
        const pattern = [identifier, "*"].join(":");
        if (ctx.cache) {
          ctx.cache.pop(identifier);
        }
        for (const db of ctx.redis) {
          await db.eval(resetScript, [pattern], [null]);
        }
      }
    });
  }
};

// src/lua-scripts/single.ts
var fixedWindowLimitScript2 = `
  local key           = KEYS[1]
  local window        = ARGV[1]
  local incrementBy   = ARGV[2] -- increment rate per request at a given value, default is 1

  local r = redis.call("INCRBY", key, incrementBy)
  if r == tonumber(incrementBy) then
  -- The first time this key is set, the value will be equal to incrementBy.
  -- So we only need the expire command once
  redis.call("PEXPIRE", key, window)
  end

  return r
`;
var fixedWindowRemainingTokensScript2 = `
      local key = KEYS[1]
      local tokens = 0

      local value = redis.call('GET', key)
      if value then
          tokens = value
      end
      return tokens
    `;
var slidingWindowLimitScript2 = `
  local currentKey  = KEYS[1]           -- identifier including prefixes
  local previousKey = KEYS[2]           -- key of the previous bucket
  local tokens      = tonumber(ARGV[1]) -- tokens per window
  local now         = ARGV[2]           -- current timestamp in milliseconds
  local window      = ARGV[3]           -- interval in milliseconds
  local incrementBy = ARGV[4]           -- increment rate per request at a given value, default is 1

  local requestsInCurrentWindow = redis.call("GET", currentKey)
  if requestsInCurrentWindow == false then
    requestsInCurrentWindow = 0
  end

  local requestsInPreviousWindow = redis.call("GET", previousKey)
  if requestsInPreviousWindow == false then
    requestsInPreviousWindow = 0
  end
  local percentageInCurrent = ( now % window ) / window
  -- weighted requests to consider from the previous window
  requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)
  if requestsInPreviousWindow + requestsInCurrentWindow >= tokens then
    return -1
  end

  local newValue = redis.call("INCRBY", currentKey, incrementBy)
  if newValue == tonumber(incrementBy) then
    -- The first time this key is set, the value will be equal to incrementBy.
    -- So we only need the expire command once
    redis.call("PEXPIRE", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second
  end
  return tokens - ( newValue + requestsInPreviousWindow )
`;
var slidingWindowRemainingTokensScript2 = `
  local currentKey  = KEYS[1]           -- identifier including prefixes
  local previousKey = KEYS[2]           -- key of the previous bucket
  local now         = ARGV[1]           -- current timestamp in milliseconds
  local window      = ARGV[2]           -- interval in milliseconds

  local requestsInCurrentWindow = redis.call("GET", currentKey)
  if requestsInCurrentWindow == false then
    requestsInCurrentWindow = 0
  end

  local requestsInPreviousWindow = redis.call("GET", previousKey)
  if requestsInPreviousWindow == false then
    requestsInPreviousWindow = 0
  end

  local percentageInCurrent = ( now % window ) / window
  -- weighted requests to consider from the previous window
  requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)

  return requestsInPreviousWindow + requestsInCurrentWindow
`;
var tokenBucketLimitScript = `
  local key         = KEYS[1]           -- identifier including prefixes
  local maxTokens   = tonumber(ARGV[1]) -- maximum number of tokens
  local interval    = tonumber(ARGV[2]) -- size of the window in milliseconds
  local refillRate  = tonumber(ARGV[3]) -- how many tokens are refilled after each interval
  local now         = tonumber(ARGV[4]) -- current timestamp in milliseconds
  local incrementBy = tonumber(ARGV[5]) -- how many tokens to consume, default is 1
        
  local bucket = redis.call("HMGET", key, "refilledAt", "tokens")
        
  local refilledAt
  local tokens

  if bucket[1] == false then
    refilledAt = now
    tokens = maxTokens
  else
    refilledAt = tonumber(bucket[1])
    tokens = tonumber(bucket[2])
  end
        
  if now >= refilledAt + interval then
    local numRefills = math.floor((now - refilledAt) / interval)
    tokens = math.min(maxTokens, tokens + numRefills * refillRate)

    refilledAt = refilledAt + numRefills * interval
  end

  if tokens == 0 then
    return {-1, refilledAt + interval}
  end

  local remaining = tokens - incrementBy
  local expireAt = math.ceil(((maxTokens - remaining) / refillRate)) * interval
        
  redis.call("HSET", key, "refilledAt", refilledAt, "tokens", remaining)
  redis.call("PEXPIRE", key, expireAt)
  return {remaining, refilledAt + interval}
`;
var tokenBucketRemainingTokensScript = `
  local key         = KEYS[1]
  local maxTokens   = tonumber(ARGV[1])
        
  local bucket = redis.call("HMGET", key, "tokens")

  if bucket[1] == false then
    return maxTokens
  end
        
  return tonumber(bucket[1])
`;
var cachedFixedWindowLimitScript = `
  local key     = KEYS[1]
  local window  = ARGV[1]
  local incrementBy   = ARGV[2] -- increment rate per request at a given value, default is 1

  local r = redis.call("INCRBY", key, incrementBy)
  if r == incrementBy then
  -- The first time this key is set, the value will be equal to incrementBy.
  -- So we only need the expire command once
  redis.call("PEXPIRE", key, window)
  end
      
  return r
`;
var cachedFixedWindowRemainingTokenScript = `
  local key = KEYS[1]
  local tokens = 0

  local value = redis.call('GET', key)
  if value then
      tokens = value
  end
  return tokens
`;

// src/single.ts
var RegionRatelimit = class extends Ratelimit {
  /**
   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithm of your choice.
   */
  constructor(config) {
    super({
      prefix: config.prefix,
      limiter: config.limiter,
      timeout: config.timeout,
      analytics: config.analytics,
      ctx: {
        redis: config.redis
      },
      ephemeralCache: config.ephemeralCache
    });
  }
  /**
   * Each request inside a fixed time increases a counter.
   * Once the counter reaches the maximum allowed number, all further requests are
   * rejected.
   *
   * **Pro:**
   *
   * - Newer requests are not starved by old ones.
   * - Low storage cost.
   *
   * **Con:**
   *
   * A burst of requests near the boundary of a window can result in a very
   * high request rate because two windows will be filled with requests quickly.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - A fixed timeframe
   */
  static fixedWindow(tokens, window) {
    const windowDuration = ms(window);
    return () => ({
      async limit(ctx, identifier, rate) {
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        if (ctx.cache) {
          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
          if (blocked) {
            return {
              success: false,
              limit: tokens,
              remaining: 0,
              reset: reset2,
              pending: Promise.resolve()
            };
          }
        }
        const incrementBy = rate ? Math.max(1, rate) : 1;
        const usedTokensAfterUpdate = await ctx.redis.eval(
          fixedWindowLimitScript2,
          [key],
          [windowDuration, incrementBy]
        );
        const success = usedTokensAfterUpdate <= tokens;
        const remainingTokens = Math.max(0, tokens - usedTokensAfterUpdate);
        const reset = (bucket + 1) * windowDuration;
        if (ctx.cache && !success) {
          ctx.cache.blockUntil(identifier, reset);
        }
        return {
          success,
          limit: tokens,
          remaining: remainingTokens,
          reset,
          pending: Promise.resolve()
        };
      },
      async getRemaining(ctx, identifier) {
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        const usedTokens = await ctx.redis.eval(
          fixedWindowRemainingTokensScript2,
          [key],
          [null]
        );
        return Math.max(0, tokens - usedTokens);
      },
      async resetTokens(ctx, identifier) {
        const pattern = [identifier, "*"].join(":");
        if (ctx.cache) {
          ctx.cache.pop(identifier);
        }
        await ctx.redis.eval(resetScript, [pattern], [null]);
      }
    });
  }
  /**
   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage
   * costs than `slidingLogs` and improved boundary behavior by calculating a
   * weighted score between two windows.
   *
   * **Pro:**
   *
   * Good performance allows this to scale to very high loads.
   *
   * **Con:**
   *
   * Nothing major.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - The duration in which the user can max X requests.
   */
  static slidingWindow(tokens, window) {
    const windowSize = ms(window);
    return () => ({
      async limit(ctx, identifier, rate) {
        const now = Date.now();
        const currentWindow = Math.floor(now / windowSize);
        const currentKey = [identifier, currentWindow].join(":");
        const previousWindow = currentWindow - 1;
        const previousKey = [identifier, previousWindow].join(":");
        if (ctx.cache) {
          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
          if (blocked) {
            return {
              success: false,
              limit: tokens,
              remaining: 0,
              reset: reset2,
              pending: Promise.resolve()
            };
          }
        }
        const incrementBy = rate ? Math.max(1, rate) : 1;
        const remainingTokens = await ctx.redis.eval(
          slidingWindowLimitScript2,
          [currentKey, previousKey],
          [tokens, now, windowSize, incrementBy]
        );
        const success = remainingTokens >= 0;
        const reset = (currentWindow + 1) * windowSize;
        if (ctx.cache && !success) {
          ctx.cache.blockUntil(identifier, reset);
        }
        return {
          success,
          limit: tokens,
          remaining: Math.max(0, remainingTokens),
          reset,
          pending: Promise.resolve()
        };
      },
      async getRemaining(ctx, identifier) {
        const now = Date.now();
        const currentWindow = Math.floor(now / windowSize);
        const currentKey = [identifier, currentWindow].join(":");
        const previousWindow = currentWindow - 1;
        const previousKey = [identifier, previousWindow].join(":");
        const usedTokens = await ctx.redis.eval(
          slidingWindowRemainingTokensScript2,
          [currentKey, previousKey],
          [now, windowSize]
        );
        return Math.max(0, tokens - usedTokens);
      },
      async resetTokens(ctx, identifier) {
        const pattern = [identifier, "*"].join(":");
        if (ctx.cache) {
          ctx.cache.pop(identifier);
        }
        await ctx.redis.eval(resetScript, [pattern], [null]);
      }
    });
  }
  /**
   * You have a bucket filled with `{maxTokens}` tokens that refills constantly
   * at `{refillRate}` per `{interval}`.
   * Every request will remove one token from the bucket and if there is no
   * token to take, the request is rejected.
   *
   * **Pro:**
   *
   * - Bursts of requests are smoothed out and you can process them at a constant
   * rate.
   * - Allows to set a higher initial burst limit by setting `maxTokens` higher
   * than `refillRate`
   */
  static tokenBucket(refillRate, interval, maxTokens) {
    const intervalDuration = ms(interval);
    return () => ({
      async limit(ctx, identifier, rate) {
        if (ctx.cache) {
          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);
          if (blocked) {
            return {
              success: false,
              limit: maxTokens,
              remaining: 0,
              reset: reset2,
              pending: Promise.resolve()
            };
          }
        }
        const now = Date.now();
        const incrementBy = rate ? Math.max(1, rate) : 1;
        const [remaining, reset] = await ctx.redis.eval(
          tokenBucketLimitScript,
          [identifier],
          [maxTokens, intervalDuration, refillRate, now, incrementBy]
        );
        const success = remaining >= 0;
        if (ctx.cache && !success) {
          ctx.cache.blockUntil(identifier, reset);
        }
        return {
          success,
          limit: maxTokens,
          remaining,
          reset,
          pending: Promise.resolve()
        };
      },
      async getRemaining(ctx, identifier) {
        const remainingTokens = await ctx.redis.eval(
          tokenBucketRemainingTokensScript,
          [identifier],
          [maxTokens]
        );
        return remainingTokens;
      },
      async resetTokens(ctx, identifier) {
        const pattern = identifier;
        if (ctx.cache) {
          ctx.cache.pop(identifier);
        }
        await ctx.redis.eval(resetScript, [pattern], [null]);
      }
    });
  }
  /**
   * cachedFixedWindow first uses the local cache to decide if a request may pass and then updates
   * it asynchronously.
   * This is experimental and not yet recommended for production use.
   *
   * @experimental
   *
   * Each request inside a fixed time increases a counter.
   * Once the counter reaches the maximum allowed number, all further requests are
   * rejected.
   *
   * **Pro:**
   *
   * - Newer requests are not starved by old ones.
   * - Low storage cost.
   *
   * **Con:**
   *
   * A burst of requests near the boundary of a window can result in a very
   * high request rate because two windows will be filled with requests quickly.
   *
   * @param tokens - How many requests a user can make in each time window.
   * @param window - A fixed timeframe
   */
  static cachedFixedWindow(tokens, window) {
    const windowDuration = ms(window);
    return () => ({
      async limit(ctx, identifier, rate) {
        if (!ctx.cache) {
          throw new Error("This algorithm requires a cache");
        }
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        const reset = (bucket + 1) * windowDuration;
        const incrementBy = rate ? Math.max(1, rate) : 1;
        const hit = typeof ctx.cache.get(key) === "number";
        if (hit) {
          const cachedTokensAfterUpdate = ctx.cache.incr(key);
          const success = cachedTokensAfterUpdate < tokens;
          const pending = success ? ctx.redis.eval(cachedFixedWindowLimitScript, [key], [windowDuration, incrementBy]).then((t) => {
            ctx.cache.set(key, t);
          }) : Promise.resolve();
          return {
            success,
            limit: tokens,
            remaining: tokens - cachedTokensAfterUpdate,
            reset,
            pending
          };
        }
        const usedTokensAfterUpdate = await ctx.redis.eval(
          cachedFixedWindowLimitScript,
          [key],
          [windowDuration, incrementBy]
        );
        ctx.cache.set(key, usedTokensAfterUpdate);
        const remaining = tokens - usedTokensAfterUpdate;
        return {
          success: remaining >= 0,
          limit: tokens,
          remaining,
          reset,
          pending: Promise.resolve()
        };
      },
      async getRemaining(ctx, identifier) {
        if (!ctx.cache) {
          throw new Error("This algorithm requires a cache");
        }
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        const hit = typeof ctx.cache.get(key) === "number";
        if (hit) {
          const cachedUsedTokens = ctx.cache.get(key) ?? 0;
          return Math.max(0, tokens - cachedUsedTokens);
        }
        const usedTokens = await ctx.redis.eval(
          cachedFixedWindowRemainingTokenScript,
          [key],
          [null]
        );
        return Math.max(0, tokens - usedTokens);
      },
      async resetTokens(ctx, identifier) {
        if (!ctx.cache) {
          throw new Error("This algorithm requires a cache");
        }
        const bucket = Math.floor(Date.now() / windowDuration);
        const key = [identifier, bucket].join(":");
        ctx.cache.pop(key);
        const pattern = [identifier, "*"].join(":");
        await ctx.redis.eval(resetScript, [pattern], [null]);
      }
    });
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  Analytics,
  MultiRegionRatelimit,
  Ratelimit
});
//# sourceMappingURL=index.js.map